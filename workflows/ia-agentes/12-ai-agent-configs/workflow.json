[
  {
    "createdAt": "2025-06-10T12:01:04.433Z",
    "updatedAt": "2025-06-10T14:09:05.000Z",
    "id": "fbt2DidDe3q2M3Mv",
    "name": "[FA] AI Agent Configs",
    "active": false,
    "isArchived": false,
    "nodes": [
      {
        "parameters": {
          "options": {}
        },
        "type": "@n8n/n8n-nodes-langchain.chatTrigger",
        "typeVersion": 1.1,
        "position": [
          0,
          0
        ],
        "id": "4908c94d-5524-4d76-8d9e-7fcd3fb3930b",
        "name": "When chat message received",
        "webhookId": "0bfa00c6-6bd3-4994-ab61-77db97ea646f"
      },
      {
        "parameters": {
          "hasOutputParser": true,
          "options": {
            "systemMessage": "You are a helpful assistant\n\nSe o usuário pedir algum fato histórico use a tool de Wikipedia",
            "maxIterations": 10,
            "returnIntermediateSteps": true,
            "passthroughBinaryImages": true,
            "batching": {
              "batchSize": 1,
              "delayBetweenBatches": 0
            }
          }
        },
        "type": "@n8n/n8n-nodes-langchain.agent",
        "typeVersion": 2,
        "position": [
          220,
          0
        ],
        "id": "fd12bd5b-f296-41be-90df-9e9bfddee06b",
        "name": "AI Agent"
      },
      {
        "parameters": {
          "content": "## Seleção de Modelo\n\nAnthropic Chat Model: Ideal para atendimento ao cliente, análise de textos extensos e fluxos que exigem ética, segurança e bom senso.\n\nAzure OpenAI Chat Model: Melhor opção para agentes corporativos integrados ao Microsoft 365, suporte interno e automações que aproveitam o Azure.\n\nAWS Bedrock Chat Model: Ótimo para agentes empresariais em ambientes AWS, integração com serviços Amazon e automações robustas na nuvem.\n\nDeepSeek Chat Model: Perfeito para agentes de pesquisa técnica, helpdesk avançado e busca de informações detalhadas.\n\nGoogle Gemini Chat Model: Indicado para agentes que usam informações da web, integração com Google Workspace e assistentes pessoais inteligentes.\n\nGoogle Vertex Chat Model: Recomendado para fluxos customizados na nuvem Google, análise de dados em larga escala e integração corporativa.\n\nGroq Chat Model: Focado em agentes que exigem respostas ultrarrápidas, como bots de atendimento instantâneo ou automações que dependem de velocidade.\n\nMistral Cloud Chat Model: Excelente para projetos open source, baixo custo, privacidade e experimentação de fluxos personalizados.\n\nOllama Chat Model: Melhor escolha para agentes locais, máxima privacidade e fluxos offline sem depender de nuvem externa.\n\nOpenRouter Chat Model: Ideal para agentes que alternam entre diferentes modelos, fluxos dinâmicos e testes de benchmarking.\n\nxAI Grok Chat Model: Para agentes experimentais, testes com LLMs inovadores e projetos que querem explorar novidades do mercado.",
          "height": 700,
          "width": 760
        },
        "type": "n8n-nodes-base.stickyNote",
        "typeVersion": 1,
        "position": [
          -620,
          200
        ],
        "id": "4782e66d-0353-4c25-9c96-62019df383b3",
        "name": "Sticky Note"
      },
      {
        "parameters": {
          "model": {
            "__rl": true,
            "mode": "list",
            "value": "gpt-4o-mini"
          },
          "options": {
            "frequencyPenalty": 1,
            "maxTokens": 300,
            "temperature": 1,
            "topP": 1
          }
        },
        "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
        "typeVersion": 1.2,
        "position": [
          200,
          300
        ],
        "id": "554abbdb-78e3-48f0-9e02-be3c6538405f",
        "name": "Alterada",
        "credentials": {
          "openAiApi": {
            "id": "H79y1c1UARm5hINL",
            "name": "OpenAi account"
          }
        }
      },
      {
        "parameters": {
          "model": {
            "__rl": true,
            "mode": "list",
            "value": "gpt-4o-mini"
          },
          "options": {}
        },
        "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
        "typeVersion": 1.2,
        "position": [
          340,
          300
        ],
        "id": "ddd93a1e-70d8-49bf-a1d9-72c6951a164e",
        "name": "OpenAI Chat Model",
        "credentials": {
          "openAiApi": {
            "id": "H79y1c1UARm5hINL",
            "name": "OpenAi account"
          }
        }
      },
      {
        "parameters": {
          "content": "## Parâmetros do modelo\n\n**Frequency Penalty:**\nControla o quanto o modelo evita repetir palavras ou frases.\n\nValor 0,0 (nenhuma penalidade): modelo pode repetir mais.\n\nValores mais altos (até 2,0): evita repetição, deixa respostas mais variadas.\nUse valores mais altos se quiser menos repetição (ex: para criar listas ou textos longos).\n\n**Maximum Number of Tokens:**\nDefine o tamanho máximo da resposta.\n\nValor -1: sem limite, modelo responde até esgotar o contexto.\n\nQualquer valor positivo (ex: 500, 1000): limita o número de tokens (palavras + pontuação).\nDefina se precisa de respostas curtas (limite baixo) ou longas (limite alto ou -1).\n\n**Sampling Temperature:**\nDefine a criatividade do modelo na geração de texto.\n\nValor 0,0: respostas super objetivas, quase sempre iguais.\n\nValor 0,7 (default): equilíbrio entre criatividade e foco.\n\nAté 1,0 ou mais: respostas muito criativas, podem variar bastante.\nUse valores baixos para tarefas técnicas, altos para brainstorm e criatividade.\n\n**Top P:**\nControla a aleatoriedade da resposta (junto da temperature).\n\nValor 1,0: considera todas as possibilidades, mais diversidade.\n\nValores menores (ex: 0,5): foca nas respostas mais prováveis, menos variedade.\nDeixe em 1,0 para respostas abertas, reduza para respostas mais “seguras”.",
          "height": 860,
          "width": 520,
          "color": 4
        },
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          200,
          440
        ],
        "typeVersion": 1,
        "id": "5def83b2-d5e1-4533-89a6-aa5e0e082637",
        "name": "Sticky Note1"
      },
      {
        "parameters": {},
        "type": "@n8n/n8n-nodes-langchain.toolWikipedia",
        "typeVersion": 1,
        "position": [
          840,
          300
        ],
        "id": "a3fd555c-a7da-416b-b13c-25af66fddeb5",
        "name": "Wikipedia"
      },
      {
        "parameters": {
          "content": "## Configurações do Agente\n\n### System Message:\nDefine a personalidade ou instrução inicial do agente de IA para cada resposta.\n\n### Max Iterations:\nLimita quantas vezes o agente pode repetir ou refinar sua tarefa no fluxo.\n\n### Return Intermediate Steps:\nMostra (ou não) os passos intermediários realizados pelo agente até o resultado final.\n\n### Automatically Passthrough Binary Images:\nPermite que imagens e arquivos binários passem pelo nó automaticamente.\n\n### Batch Processing:\nHabilita o processamento de vários itens de uma vez, em lote, dentro do fluxo.",
          "height": 360,
          "width": 600,
          "color": 3
        },
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          220,
          -380
        ],
        "typeVersion": 1,
        "id": "4ecfbfc3-b567-4e03-a92a-b2bb97818340",
        "name": "Sticky Note2"
      },
      {
        "parameters": {},
        "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
        "typeVersion": 1.3,
        "position": [
          860,
          540
        ],
        "id": "f31b474f-170f-4916-826f-6505623fd142",
        "name": "Simple Memory"
      },
      {
        "parameters": {
          "content": "## Memória\n\n### Memória Padrão do n8n:\n\nO n8n armazena dados e históricos de execução em um banco de dados SQLite local por padrão, ideal apenas para testes e uso pessoal.\n\n### Melhor Memória para Produção:\n\nO recomendado para ambientes de produção é usar bancos de dados robustos como PostgreSQL ou MySQL, garantindo mais estabilidade, performance e segurança para volumes maiores e múltiplos usuários.",
          "height": 340,
          "width": 640,
          "color": 6
        },
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          980,
          460
        ],
        "typeVersion": 1,
        "id": "634e9077-a1d8-4375-a456-42400b651514",
        "name": "Sticky Note3"
      },
      {
        "parameters": {
          "jsonSchemaExample": "{\n\t\"nome\": \"Nome do usuário\",\n\t\"idade\": 33,\n    \"hobbies\": [\"hobbie 1\", \"Hobbie 2\"]\n}"
        },
        "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
        "typeVersion": 1.2,
        "position": [
          1120,
          140
        ],
        "id": "60224f18-d994-4aa5-9356-6a287d206110",
        "name": "Structured Output Parser"
      },
      {
        "parameters": {},
        "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
        "typeVersion": 2.2,
        "position": [
          1020,
          280
        ],
        "id": "0636b568-f425-442f-9a2e-8353285b11ac",
        "name": "Call n8n Workflow Tool"
      }
    ],
    "connections": {
      "When chat message received": {
        "main": [
          [
            {
              "node": "AI Agent",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Alterada": {
        "ai_languageModel": [
          []
        ]
      },
      "OpenAI Chat Model": {
        "ai_languageModel": [
          [
            {
              "node": "AI Agent",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      },
      "Wikipedia": {
        "ai_tool": [
          [
            {
              "node": "AI Agent",
              "type": "ai_tool",
              "index": 0
            }
          ]
        ]
      },
      "Simple Memory": {
        "ai_memory": [
          [
            {
              "node": "AI Agent",
              "type": "ai_memory",
              "index": 0
            }
          ]
        ]
      },
      "Structured Output Parser": {
        "ai_outputParser": [
          [
            {
              "node": "AI Agent",
              "type": "ai_outputParser",
              "index": 0
            }
          ]
        ]
      },
      "Call n8n Workflow Tool": {
        "ai_tool": [
          [
            {
              "node": "AI Agent",
              "type": "ai_tool",
              "index": 0
            }
          ]
        ]
      }
    },
    "settings": {
      "executionOrder": "v1"
    },
    "staticData": null,
    "meta": {
      "templateCredsSetupCompleted": true
    },
    "pinData": {},
    "versionId": "367846a0-afd2-466b-9017-0e283aeadb7b",
    "triggerCount": 0,
    "tags": [
      {
        "createdAt": "2025-05-26T19:48:27.869Z",
        "updatedAt": "2025-05-26T19:48:27.869Z",
        "id": "hbBJw9VpX8CbCKpn",
        "name": "FA"
      }
    ]
  }
]